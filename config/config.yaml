train:
  epochs: 10
  batch: 32

  scheduler: constant
  warmup: 0.01
  lr: 0.0001

test:
  batch: 64

model:
  dim: 768
  max_len: 512

  positional:
    dropout: 0.3

  encoder:
    layer_num: 6
    head_num: 12
    fc_dim: 3072
    dropout: 0.1

    gate:
      path: "model.gate.nvidia"

  decoder:
    layer_num: 2
    head_num: 2
    fc_dim: 3072
    dropout: 0.1

  classifier:
    dropout: 0.1

tokenizer:
  path: "google-bert/bert-base-uncased"
  vocab: 30522
  mask: 103
  pad: 0

dataset:
  path: "Yelp/yelp_review_full"
  text_col: "text"

checkpoint:
  interval: 15
  output: "output"

log:
  k: 100
