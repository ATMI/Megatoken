train:
  epochs: 10
  batch: 4

  scheduler: linear
  warmup: 0.1
  lr: 0.0001

test:
  batch: 256

model:
  dim: 32
  max_len: 512

  positional:
    dropout: 0.3

  encoder:
    layer_num: 2
    head_num: 2
    fc_dim: 64
    dropout: 0.1

    gate:
      path: "model.gate.nvidia"


  decoder:
    layer_num: 2
    head_num: 2
    fc_dim: 64
    dropout: 0.1

  classifier:
    dropout: 0.3

tokenizer:
  path: "FacebookAI/roberta-base"
  vocab: 50265
  mask: 2
  pad: 1

dataset:
  path: "Yelp/yelp_review_full"
  text_col: "text"
