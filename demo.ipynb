{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# CoTA: Compression Transformer Autoencoder\n",
   "id": "d96ffc644a4ba5bc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "CoTA introduces a novel approach to representing sequential data. Instead of relying on a single vector, CoTA utilizes a variable number of embedding vectors. This method enhances the preservation of details and maintains the order more effectively.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "| ![bert_encoder.png](readme/images/bert_encoder.png) | ![cot_encoder.png](readme/images/cot_encoder.png) |\n",
    "|:------------------------------------------------------:|:----------------------------------------------------:|\n",
    "|                    Typical encoder                     |                     CoTA encoder                     |"
   ],
   "id": "4684b98cb68cf17a"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-20T22:24:23.971587Z",
     "start_time": "2025-04-20T22:24:19.874482Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.autoencoder.inference import inference, get_memory\n",
    "from src.autoencoder.model import Model as CoTA\n",
    "from src.autoencoder.config import Config\n",
    "from src.classifier.model import Classifier\n",
    "from src.util import prepare\n",
    "\n",
    "from src.autoencoder.viz import viz"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Preparations",
   "id": "5d1686ee20b37e41"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T22:24:24.290189Z",
     "start_time": "2025-04-20T22:24:23.975425Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prepare.rnd(Config.seed)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(Config.model)"
   ],
   "id": "f5a1c375b762adbc",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T22:24:24.385255Z",
     "start_time": "2025-04-20T22:24:24.383390Z"
    }
   },
   "cell_type": "code",
   "source": [
    "examples = (\n",
    "\t\"Very disappointed in the customer service. We ordered Reuben's and wanted coleslaw instead of kraut. They charged us $3.00 for the coleslaw. We will not be back . The iced tea is also terrible tasting.\",\n",
    "\n",
    "\t\"This place is so nice! The dishes are delicious. I especially recommend trying beef stroganoff!\",\n",
    ")"
   ],
   "id": "1af55d9ec46b4c16",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Inference\n",
   "id": "7c5cc4dc3dd3954a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T22:24:26.741284Z",
     "start_time": "2025-04-20T22:24:24.426491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ckpt = \"checkpoint/29249.pth\"\n",
    "checkpoint = torch.load(ckpt, weights_only=True, map_location=device)\n",
    "\n",
    "cota_model = CoTA(Config.model, Config.bias, Config.temperature)\n",
    "cota_model.load_state_dict(checkpoint[\"model\"])\n",
    "cota_model.eval();"
   ],
   "id": "2f23f06b08c4b654",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T22:24:28.061873Z",
     "start_time": "2025-04-20T22:24:26.876771Z"
    }
   },
   "cell_type": "code",
   "source": "inference(cota_model, tokenizer, examples[0])",
   "id": "9b8a5dc1ed14c9a3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial length: 52\n",
      "Compression rate: 0.23\n",
      "Output size: 12\n",
      "\n",
      "Initial text:\n",
      "Very disappointed in the customer service. We ordered Reuben's and wanted coleslaw instead of kraut. They charged us $3.00 for the coleslaw. We will not be back . The iced tea is also terrible tasting.\n",
      "Predicted:\n",
      "Very disappointed in the customer service. We ordered Reuben's and wanted coleslaw instead of kraut. They charged us $3.00 for the coleslaw. I won't be back. The iced tea is also terrible tasting.\n",
      "==================================================\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Mask",
   "id": "69ebc8b5cefa3ff7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T22:24:28.201073Z",
     "start_time": "2025-04-20T22:24:28.197734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_matrix(matrix, figsize, title):\n",
    "\tmatrix_for_plot = np.where(np.isneginf(matrix), -1, matrix)\n",
    "\tplt.figure(figsize=figsize)\n",
    "\tsns.heatmap(matrix_for_plot, annot=True, cmap=\"rocket_r\", cbar=False)\n",
    "\tplt.title(title)\n",
    "\tplt.xticks(rotation=90)\n",
    "\tplt.show()\n",
    "\n",
    "\n",
    "def plot_masks(memory):\n",
    "\tgate_mask = torch.exp(memory.gate_mask.detach().cpu()).numpy()\n",
    "\tplot_matrix(gate_mask, (20, 1), \"Gate Mask\")\n",
    "\n",
    "\tattn_mask = memory.attn_scores[-1].detach().cpu().numpy()\n",
    "\tmatrix = attn_mask.mean(0)\n",
    "\tplot_matrix(matrix, (16, 16), \"Last layer Attention Mask\")"
   ],
   "id": "f9fa2e794c4ba451",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Sentiment Classification",
   "id": "c1761a4ff34310f5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T22:24:28.353659Z",
     "start_time": "2025-04-20T22:24:28.348229Z"
    }
   },
   "cell_type": "code",
   "source": [
    "classifier = Classifier()\n",
    "classifier = classifier.to(device)\n",
    "\n",
    "init = \"checkpoint/1_classifier.pth\"\n",
    "init = torch.load(init, map_location=device, weights_only=True)\n",
    "classifier.load_state_dict(init)\n",
    "classifier.eval();"
   ],
   "id": "e78ad8b201fbd414",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T22:27:01.088149Z",
     "start_time": "2025-04-20T22:27:01.084280Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def classify(compressed_seq):\n",
    "\twith torch.no_grad():\n",
    "\t\tembeds = compressed_seq.embeds.squeeze(0)\n",
    "\t\tindex = torch.tensor([0] * len(embeds), dtype=torch.long).to(device)\n",
    "\t\tlogits = classifier.forward(embeds, index)\n",
    "\n",
    "\tprob = torch.sigmoid(logits).item()\n",
    "\tsentiment = \"Positive\" if prob > 0.5 else \"Negative\"\n",
    "\tprob = prob if sentiment == \"Positive\" else 1.0 - prob\n",
    "\tprint(f\"\\nSentiment: {sentiment} ({prob:.2%} confidence)\")"
   ],
   "id": "d8d9c73ccc8bb867",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T22:27:12.258330Z",
     "start_time": "2025-04-20T22:27:11.843573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def demo(text):\n",
    "\tinference(cota_model, tokenizer, text)\n",
    "\tviz(cota_model, tokenizer, text)\n",
    "\n",
    "\tcompressed_seq = get_memory(cota_model, tokenizer, text, device, return_tokens=False)\n",
    "\tclassify(compressed_seq)\n",
    "\n",
    "demo(examples[1])"
   ],
   "id": "b6af75db0813cf4e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial length: 22\n",
      "Compression rate: 0.14\n",
      "Output size: 3\n",
      "\n",
      "Initial text:\n",
      "This place is so nice! The dishes are delicious. I especially recommend trying beef stroganoff!\n",
      "Predicted:\n",
      "This place is so nice! The food is delicious. And the portions are great for dessert strogano!\n",
      "==================================================\n",
      "Layer 0:\n",
      "No compression in this layer!\n",
      "\n",
      "Layer 1:\n",
      "- Eliminated token: '▁place', (position: 1)\n",
      "\t\t1. Merged into '</s>' (score: 0.4648)\n",
      "\t\t2. Merged into '▁This' (score: 0.2420)\n",
      "\t\t3. Merged into '!' (score: 0.0897)\n",
      "- Eliminated token: '▁is', (position: 2)\n",
      "\t\t1. Merged into '</s>' (score: 0.4989)\n",
      "\t\t2. Merged into '▁This' (score: 0.2224)\n",
      "\t\t3. Merged into '▁place' (score: 0.0801)\n",
      "- Eliminated token: '▁so', (position: 3)\n",
      "\t\t1. Merged into '</s>' (score: 0.4354)\n",
      "\t\t2. Merged into '▁is' (score: 0.1678)\n",
      "\t\t3. Merged into '▁This' (score: 0.0901)\n",
      "- Eliminated token: '▁The', (position: 6)\n",
      "\t\t1. Merged into '</s>' (score: 0.5865)\n",
      "\t\t2. Merged into '!' (score: 0.0765)\n",
      "\t\t3. Merged into '▁nice' (score: 0.0764)\n",
      "- Eliminated token: '▁are', (position: 8)\n",
      "\t\t1. Merged into '</s>' (score: 0.4544)\n",
      "\t\t2. Merged into '▁The' (score: 0.1861)\n",
      "\t\t3. Merged into '▁dishes' (score: 0.1245)\n",
      "- Eliminated token: '.', (position: 10)\n",
      "\t\t1. Merged into '</s>' (score: 0.3283)\n",
      "\t\t2. Merged into '▁delicious' (score: 0.1346)\n",
      "\t\t3. Merged into '▁The' (score: 0.1234)\n",
      "- Eliminated token: '▁I', (position: 11)\n",
      "\t\t1. Merged into '</s>' (score: 0.3447)\n",
      "\t\t2. Merged into '.' (score: 0.1880)\n",
      "\t\t3. Merged into '▁The' (score: 0.1117)\n",
      "- Eliminated token: '▁recommend', (position: 13)\n",
      "\t\t1. Merged into '</s>' (score: 0.2064)\n",
      "\t\t2. Merged into '▁especially' (score: 0.1801)\n",
      "\t\t3. Merged into '▁trying' (score: 0.1308)\n",
      "- Eliminated token: '▁', (position: 16)\n",
      "\t\t1. Merged into '▁trying' (score: 0.3159)\n",
      "\t\t2. Merged into 'stro' (score: 0.1647)\n",
      "\t\t3. Merged into '▁beef' (score: 0.1634)\n",
      "\n",
      "Compressed sequence after layer 1:\n",
      "This nice! dishes delicious especially trying beefstroganoff!</s>\n",
      "--------------------------------------------------\n",
      "\n",
      "Layer 2:\n",
      "- Eliminated token: '▁This', (position: 0)\n",
      "\t\t1. Merged into '</s>' (score: 0.6949)\n",
      "\t\t2. Merged into '▁place' (score: 0.0625)\n",
      "\t\t3. Merged into '!' (score: 0.0289)\n",
      "- Eliminated token: '!', (position: 5)\n",
      "\t\t1. Merged into '</s>' (score: 0.2344)\n",
      "\t\t2. Merged into '▁nice' (score: 0.1640)\n",
      "\t\t3. Merged into '▁so' (score: 0.0935)\n",
      "- Eliminated token: '▁dishes', (position: 7)\n",
      "\t\t1. Merged into '▁The' (score: 0.2661)\n",
      "\t\t2. Merged into '!' (score: 0.1024)\n",
      "\t\t3. Merged into '▁nice' (score: 0.0868)\n",
      "- Eliminated token: '▁trying', (position: 14)\n",
      "\t\t1. Merged into '▁recommend' (score: 0.2234)\n",
      "\t\t2. Merged into '</s>' (score: 0.0939)\n",
      "\t\t3. Merged into '▁beef' (score: 0.0880)\n",
      "- Eliminated token: '▁beef', (position: 15)\n",
      "\t\t1. Merged into '▁trying' (score: 0.2875)\n",
      "\t\t2. Merged into '</s>' (score: 0.0988)\n",
      "\t\t3. Merged into 'stro' (score: 0.0968)\n",
      "- Eliminated token: 'gan', (position: 18)\n",
      "\t\t1. Merged into 'stro' (score: 0.2844)\n",
      "\t\t2. Merged into 'off' (score: 0.1321)\n",
      "\t\t3. Merged into '▁beef' (score: 0.1175)\n",
      "- Eliminated token: 'off', (position: 19)\n",
      "\t\t1. Merged into 'gan' (score: 0.1601)\n",
      "\t\t2. Merged into '!' (score: 0.1191)\n",
      "\t\t3. Merged into 'stro' (score: 0.1190)\n",
      "- Eliminated token: '!', (position: 20)\n",
      "\t\t1. Merged into '</s>' (score: 0.2606)\n",
      "\t\t2. Merged into '▁' (score: 0.1147)\n",
      "\t\t3. Merged into 'off' (score: 0.0864)\n",
      "\n",
      "Compressed sequence after layer 2:\n",
      "nice delicious especiallystro</s>\n",
      "--------------------------------------------------\n",
      "\n",
      "Layer 3:\n",
      "- Eliminated token: '▁nice', (position: 4)\n",
      "\t\t1. Merged into '</s>' (score: 0.3949)\n",
      "\t\t2. Merged into '▁This' (score: 0.3056)\n",
      "\t\t3. Merged into '!' (score: 0.1114)\n",
      "- Eliminated token: '▁especially', (position: 12)\n",
      "\t\t1. Merged into '</s>' (score: 0.4753)\n",
      "\t\t2. Merged into '▁delicious' (score: 0.1445)\n",
      "\t\t3. Merged into '▁nice' (score: 0.0947)\n",
      "\n",
      "Compressed sequence after layer 3:\n",
      "deliciousstro</s>\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "==================================================\n",
      "Initial Sequence:\n",
      "This place is so nice! The dishes are delicious. I especially recommend trying beef stroganoff!</s>\n",
      "\n",
      "Final compressed text:\n",
      "deliciousstro</s>\n",
      "==================================================\n",
      "\n",
      "Sentiment: Positive (96.97% confidence)\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T22:27:15.678094Z",
     "start_time": "2025-04-20T22:27:15.675695Z"
    }
   },
   "cell_type": "code",
   "source": "# plot_masks(compressed_seq)",
   "id": "1317f3ea3623a6e7",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Interactive Mode",
   "id": "467b84395dfc2f1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def interactive():\n",
    "\tprint(\"\\n--- CoTA Interactive Demo ---\")\n",
    "\tprint(\"Type 'exit' to end the session\\n\")\n",
    "\n",
    "\twhile True:\n",
    "\t\ttext = input(\"> \")\n",
    "\t\tif text.lower() == 'exit':\n",
    "\t\t\tbreak\n",
    "\n",
    "\t\tif not text.lower():\n",
    "\t\t\tprint(\"Incorrect input!\")\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\tinference(cota_model, tokenizer, text)\n",
    "\t\tclassify(text)\n",
    "\t\tprint(\"-\" * 50)\n",
    "\n",
    "interactive()"
   ],
   "id": "ae12a27e0f18c1a4",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
